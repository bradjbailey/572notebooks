{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91effe7b",
   "metadata": {},
   "source": [
    "# Investigating Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc5ac78",
   "metadata": {},
   "source": [
    "We'll be looking at different networks to discuss their differences, advantages, and what they look like. For this we will use the `torchvision` and `timm` packages from python as these pacakges have a substantial amount of vision models and are the de facto places one should look for when vision models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7ff5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "447cbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "import timm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392ff158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09c85d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../Datasets\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b70f853c0b44c758a965af60e48277e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Datasets\\cifar-10-python.tar.gz to ../Datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbrad\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:478: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = T.ToTensor()\n",
    "trainset = torchvision.datasets.CIFAR10('../Datasets', download=True, transform=transform)\n",
    "train = torch.utils.data.DataLoader(trainset, batch_size=32, num_workers=12)\n",
    "\n",
    "expand_transform = T.Compose([T.Resize(256), T.ToTensor()])\n",
    "trainset_256 = torchvision.datasets.CIFAR10('../Datasets', download=True, transform=expand_transform)\n",
    "train_256 = torch.utils.data.DataLoader(trainset_256, batch_size=32, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4720e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train)\n",
    "imgs, labels = dataiter.next()\n",
    "img_grid = torchvision.utils.make_grid(imgs)\n",
    "matplotlib_imshow(img_grid)\n",
    "\n",
    "dataiter_256 = iter(train_256)\n",
    "imgs_256, labels_256 = dataiter_256.next()\n",
    "img_grid_256 = torchvision.utils.make_grid(imgs_256)\n",
    "matplotlib_imshow(img_grid_256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb39b4",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec7eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(            \n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=389880, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=n_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        print(x.shape)\n",
    "        logits = self.classifier(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa166a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = LeNet5(10)\n",
    "lewriter = SummaryWriter(\"lenet\")\n",
    "lewriter.add_image('cifar', img_grid_256)\n",
    "lewriter.add_graph(lenet, imgs_256)\n",
    "%tensorboard --logdir lenet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e263d74",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c63f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex = torchvision.models.alexnet(pretrained=True)\n",
    "alex_writer = SummaryWriter(\"alex\")\n",
    "alex_writer.add_image('cifar', img_grid_256)\n",
    "alex_writer.add_graph(alex, imgs_256)\n",
    "\n",
    "%tensorboard --logdir alex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445a839f",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104902c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = torchvision.models.vgg19(pretrained=True)\n",
    "vgg_writer = SummaryWriter(\"vgg\")\n",
    "vgg_writer.add_image('cifar', img_grid_256)\n",
    "vgg_writer.add_graph(vgg, imgs_256)\n",
    "\n",
    "%tensorboard --logdir vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe79e5",
   "metadata": {},
   "source": [
    "# GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "google = torchvision.models.googlenet()\n",
    "goog_writer = SummaryWriter(\"google\")\n",
    "goog_writer.add_image('cifar', img_grid_256)\n",
    "goog_writer.add_graph(google, imgs_256)\n",
    "\n",
    "%tensorboard --logdir google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34634c0f",
   "metadata": {},
   "source": [
    "# ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dceecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = timm.create_model('resnet34')\n",
    "res_writer = SummaryWriter(\"resnet\")\n",
    "\n",
    "res_writer.add_image('cifar', img_grid)\n",
    "\n",
    "\n",
    "res_writer.add_graph(resnet, imgs)\n",
    "\n",
    "%tensorboard --logdir resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c89da",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = timm.create_model('mobilenetv3_large_075', pretrained=True)\n",
    "mob_writer = SummaryWriter(\"mobilenet\")\n",
    "mob_writer.add_image('cifar', img_grid_256)\n",
    "mob_writer.add_graph(mobile, imgs_256)\n",
    "\n",
    "%tensorboard --logdir mobilenet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95968ce0",
   "metadata": {},
   "source": [
    "# Looking at Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5962dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd989584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG was trained on ImageNet, but let's use CIFAR-10\n",
    "vgg.classifier[6] = nn.Linear(4096, 10)\n",
    "vgg.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e017ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    for idx in np.arange(16):\n",
    "        ax = fig.add_subplot(4, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx])\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53374942",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg_writer.add_figure('predictions vs actual',\n",
    "                     plot_classes_preds(vgg, imgs_256, labels_256),\n",
    "                     global_step=1\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edfb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c29fa17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6926e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e50b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68851d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
